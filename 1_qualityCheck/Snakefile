subworkflow downloadReference:
    workdir: "../data/referenceGenome"
    snakefile: "../data/referenceGenome/Snakefile"

import datetime as dt
now=dt.datetime.now()
date=now.strftime('%Y-%m-%d')
time=now.strftime('%H:%M:%S')

SAMPLES = set()

#### get sample names from server
#import ftplib as ftp # Dateien vom Server holen / import JSONs from server
#import os
#json_server=ftp.FTP(config['url'])
#json_server.login(config['login'],config['password'])
#
#directory='/'
#json_server.cwd(directory)
#ftp_filelist=json_server.nlst(directory)
#
#directory='/'
#json_server.cwd(directory)
#ftp_filelist=json_server.nlst(directory)
#
## iterate over remote files
#for filename in ftp_filelist:
#    if filename[-5:]=='.json':
#        SAMPLES.add(os.path.splitext(filename)[0])


debug="Results"
jsonsoriginal="json/original"
mappedjsons="json/mapped"
results="json/currated"

onstart:
    print("Start running backup")
    shell(
    """
    mkdir -p json/backup;
	mkdir -p {jsonsoriginal}
    touch {jsonsoriginal}/empty.json;
    tar -cvzf json/backup/original{date}{time}.tar.gz {jsonsoriginal}/*.json;
    rm {jsonsoriginal}/empty.json;
	mkdir -p {results}
    touch {results}/empty.json;
    tar -cvzf json/backup/currated{date}{time}.tar.gz {results}/*.json;
    rm {results}/empty.json;
	mkdir -p {mappedjsons}
    touch {mappedjsons}/empty.json;
    tar -cvzf json/backup/mapped{date}{time}.tar.gz {mappedjsons}/*.json;
    rm {mappedjsons}/empty.json;
    """
    )
    print("Backup ready")

rule all:
    input:
        "variants.vcf",
        "../data/PEDIA/mutations/variants.vcf.gz",
        touch(jsonsoriginal + '/download.done'),
        "config.yml",
        touch(results+"/currated.done"),
        expand("json/currated/{sample}.json", sample=SAMPLES),
        "hgvs_error_report.csv"

# Download jsons
rule downloadJSONs:
    input:
        script = "scripts/download.py"
    output:
        done = touch(jsonsoriginal + '/download.done')
    params:
        output = "json/original/"
    shell:
        """
        python {input.script} {params.output}
        """

#Mapping to old JSON-Format
rule runMapping:
    input:
        scripts = "scripts/mapping.py"
    output:
        done = touch("Mapping.done")
    params:
        jsonsoriginal=jsonsoriginal,
        mappedjsons=mappedjsons,
        vcf_folder="../data/PEDIA/vcfs/original/",
        err_dict="hgvs_errors.json",
        err_dict_partial="hgvs_partial.json"
    shell:
        """
        python2 {input.scripts} --jsonsoriginal {params.jsonsoriginal} --mappedjsons {params.mappedjsons} --vcf {params.vcf_folder} --errjson {params.err_dict} --errpartialjson {params.err_dict_partial}
        """

# Run the quality check.
rule runQuality:
    input:
        script = "scripts/JsonsQC.py",
        mapping = "Mapping.done"
    output:
        vcf = "variants.vcf",
        config = "config.yml",
        currated = touch(results+"/currated.done"),
        errordict = "hgvs_error_report.csv"
    params:
        mappedjsons=mappedjsons,
        results=results
    shell:
        """
        python2 {input.script} --mappedjsons {params.mappedjsons} --output {params.results} --errorlog {output.errordict} --vcf {output.vcf} --sample {output.config}
        """

rule multiVCF:
    input:
        currated = results+"/currated.done",
        vcf = "variants.vcf"
    output:
        mutation_vcf = "../data/PEDIA/mutations/variants.vcf.gz",
    shell:
        """
        bgzip -c {input.vcf} > {output.mutation_vcf}
        """
