; General workflow configuration
[general]
logfile = preprocess.log
; create pickle archives of case list
dump_intermediate = false
; path of data folder
data_path = data

[classifier]
; training pickle file
train_pickle_path = data/train/train_v1.2.p
; param c
param_c = 0.015625

[input]
; download files from aws
download = false

; general structure in output path
[output]
; destination of all converted old jsons
converted_path = jsons/phenomized
; summary of all vcf files
vcf_config_file = config.yml
; generated from hgvs strings
simulated_vcf_path = mutations
; user provided real vcf information
real_vcf_path = vcfs/original

; quality check logging output as json format
quality_check_log = quality_check.json
; output directory for cases passing quality check
valid_case_path = process/checked

[pedia]
; necessary for download of data from your lab
; you can remove this part if you don't use LAB api
lab_id =
key =
secret =
download_path = process/lab/pedia
; location for possible raw json file overrides
corrected_path = process/lab/pedia/corrected
output = output/PEDIA

[omim]
; necessary for download of morbidmap
mimdir = data/omim
mim2gene_hash = b852756f44f9855b49e296940deb7f6b
morbidmap_hash = bb8bd0f00010c49489734d1aa4e9dc08

[jannovar]
url = localhost
port = 8888

[phenomizer]
; addition of phenomization scores based on HPO terms
url = 
user = 
password = 

; Specific QC configuration
[errorfixer]
; override genomic entry information with manually corrected information
error_path = hgvs_errors.json
new_error_path = hgvs_new_errors.json
